{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea816ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import (\n",
    "    Dict,\n",
    "    List,\n",
    "    Protocol,\n",
    "    Sequence,\n",
    "    Tuple,\n",
    "    TypedDict,\n",
    "    Optional,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "\n",
    "from daft_func import Pipeline, func, NestedPipeline\n",
    "\n",
    "# ---- Core vector type -------------------------------------------------------\n",
    "Vector = npt.NDArray[np.float32]\n",
    "\n",
    "\n",
    "# ---- Protocols -------------------------------------------------------------\n",
    "class Encoder(Protocol):\n",
    "    dim: int\n",
    "\n",
    "    def encode(self, text: str) -> Vector: ...\n",
    "\n",
    "\n",
    "class Indexer(Protocol):\n",
    "    def index(self, encoded: Sequence[\"EncodedPassage\"]) -> \"BaseIndex\": ...\n",
    "\n",
    "\n",
    "class Reranker(Protocol):\n",
    "    def rerank(\n",
    "        self, query: \"Query\", hits: Sequence[\"RetrievedDoc\"], top_k: int | None = None\n",
    "    ) -> List[\"RetrievedDoc\"]: ...\n",
    "\n",
    "\n",
    "# ---- Data models ------------------------------------------------------------\n",
    "@dataclass(frozen=True)\n",
    "class Passage:\n",
    "    pid: str\n",
    "    text: str\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EncodedPassage:\n",
    "    pid: str\n",
    "    text: str\n",
    "    embedding: Vector\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Query:\n",
    "    text: str\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class RetrievedDoc:\n",
    "    pid: str\n",
    "    text: str\n",
    "    embedding: Vector\n",
    "    score: float\n",
    "\n",
    "\n",
    "class SearchHit(TypedDict):\n",
    "    pid: str\n",
    "    score: float\n",
    "\n",
    "\n",
    "class BaseIndex(Protocol):\n",
    "    dim: int\n",
    "\n",
    "    def add(self, items: Sequence[EncodedPassage]) -> None: ...\n",
    "    def search(self, query_vec: Vector, top_k: int = 10) -> List[SearchHit]: ...\n",
    "    def get(self, pid: str) -> EncodedPassage: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a32c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Implementations -------------------------------------------------------\n",
    "class NumpyRandomEncoder:\n",
    "    def __init__(self, dim: int = 4, rng: np.random.Generator | None = None) -> None:\n",
    "        self.dim = dim\n",
    "        self._rng = rng or np.random.default_rng()\n",
    "\n",
    "    def encode(self, text: str) -> Vector:\n",
    "        return self._rng.random(self.dim, dtype=np.float32)\n",
    "\n",
    "\n",
    "class InMemoryIndex:\n",
    "    def __init__(self, dim: int) -> None:\n",
    "        self.dim = dim\n",
    "        self._data: Dict[str, EncodedPassage] = {}\n",
    "\n",
    "    def add(self, items: Sequence[EncodedPassage]) -> None:\n",
    "        for it in items:\n",
    "            self._data[it.pid] = it\n",
    "\n",
    "    def search(self, query_vec: Vector, top_k: int = 10) -> List[SearchHit]:\n",
    "        q = query_vec / (np.linalg.norm(query_vec) + 1e-12)\n",
    "        hits: List[Tuple[str, float]] = []\n",
    "        for pid, ep in self._data.items():\n",
    "            v = ep.embedding / (np.linalg.norm(ep.embedding) + 1e-12)\n",
    "            hits.append((pid, float(np.dot(q, v))))\n",
    "        hits.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [{\"pid\": pid, \"score\": score} for pid, score in hits[:top_k]]\n",
    "\n",
    "    def get(self, pid: str) -> EncodedPassage:\n",
    "        return self._data[pid]\n",
    "\n",
    "\n",
    "class SimpleIndexer:\n",
    "    def __init__(self, dim: int) -> None:\n",
    "        self.dim = dim\n",
    "\n",
    "    def index(self, encoded: Sequence[EncodedPassage]) -> BaseIndex:\n",
    "        idx = InMemoryIndex(self.dim)\n",
    "        idx.add(encoded)\n",
    "        return idx\n",
    "\n",
    "\n",
    "class IdentityReranker:\n",
    "    def rerank(\n",
    "        self, query: Query, hits: Sequence[RetrievedDoc], top_k: int | None = None\n",
    "    ) -> List[RetrievedDoc]:\n",
    "        out = list(hits)\n",
    "        if top_k is not None:\n",
    "            out = out[:top_k]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62616117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Encode Pipeline ---------------------------------------------\n",
    "@func(output=\"cleaned_text\")\n",
    "def clean_text(passage: Passage) -> str:\n",
    "    return passage.text.strip().lower()\n",
    "\n",
    "\n",
    "@func(output=\"embedding\")\n",
    "def encode_text(encoder: Encoder, cleaned_text: str, is_query: bool = False) -> Vector:\n",
    "    return encoder.encode(cleaned_text, is_query)\n",
    "\n",
    "\n",
    "@func(output=\"encoded_passage\")\n",
    "def pack_encoded(passage: Passage, embedding: Vector) -> EncodedPassage:\n",
    "    return EncodedPassage(pid=passage.pid, text=passage.text, embedding=embedding)\n",
    "\n",
    "\n",
    "single_encode = Pipeline(functions=[clean_text, encode_text, pack_encoded])\n",
    "single_encode.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aebd71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = single_encode.run(\n",
    "    inputs={\"passage\": Passage(pid=\"1\", text=\"hello\"), \"encoder\": Encoder()}\n",
    ")  # should return a dict with keys as output names and corresponding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42625002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res == {\n",
    "#     \"cleaned_text\": \"hello\",\n",
    "#     \"encoded_text\": np.ndarray([...])\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3660c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_encode.map(\n",
    "    inputs={\n",
    "        \"passage\": [Passage(pid=\"1\", text=\"hello\"), Passage(pid=\"2\", text=\"world\")],\n",
    "        \"encoder\": Encoder(),\n",
    "    },\n",
    "    map_over=\"passage\",\n",
    ")  # this should return a dict with keys as output names and corresponding lists of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2ffd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res == {\n",
    "#     \"cleaned_text\": [\"hello\", \"world\"],\n",
    "#     \"encoded_text\": [\n",
    "#         np.ndarray([...]),  # embedding for \"hello\"\n",
    "#         np.ndarray([...])   # embedding for \"world\"\n",
    "#     ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41828a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Index\n",
    "encode_corpus = NestedPipeline(\n",
    "    pipeline=single_encode,\n",
    "    inputs={\"corpus\": \"passage\"},\n",
    "    outputs={\"encoded_passage\": \"encoded_corpus\"},\n",
    "    map_over=\"corpus\",\n",
    ")\n",
    "\n",
    "\n",
    "@node(output=\"index\")\n",
    "def build_index(\n",
    "    indexer: Indexer, encoded_corpus: Sequence[EncodedPassage]\n",
    ") -> BaseIndex:\n",
    "    return indexer.index(encoded_corpus)\n",
    "\n",
    "\n",
    "# Take the mapped EncodedPassage list and build an index\n",
    "encode_and_index = Pipeline(nodes=[encode_corpus, build_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47832aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy data\n",
    "corpus: List[Passage] = [\n",
    "    Passage(pid=\"p1\", text=\"Hello World\"),\n",
    "    Passage(pid=\"p2\", text=\"The Quick Brown Fox\"),\n",
    "]\n",
    "\n",
    "encoder = NumpyRandomEncoder(dim=4)\n",
    "indexer = SimpleIndexer(dim=encoder.dim)\n",
    "encode_and_index.visualize()\n",
    "\n",
    "outputs = encode_and_index.run(\n",
    "    inputs={\n",
    "        \"corpus\": corpus,\n",
    "        \"encoder\": encoder,\n",
    "        \"indexer\": indexer,\n",
    "    }\n",
    ")\n",
    "index: BaseIndex = outputs[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca833443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Retrieval + Reranking --------------------------------------------------\n",
    "encode_query = NestedPipeline(\n",
    "    pipeline=single_encode,\n",
    "    inputs={\"query.text\": \"text\"},\n",
    "    outputs={\"encoded_passage\": \"query_vec\"},\n",
    ")\n",
    "\n",
    "\n",
    "@func(output=\"retrieved\")\n",
    "def retrieve(\n",
    "    index: BaseIndex, query_vec: Vector, top_k: int = 10\n",
    ") -> List[RetrievedDoc]:\n",
    "    hits = index.search(query_vec, top_k=top_k)\n",
    "    return [\n",
    "        RetrievedDoc(\n",
    "            pid=h[\"pid\"],\n",
    "            text=index.get(h[\"pid\"]).text,\n",
    "            embedding=index.get(h[\"pid\"]).embedding,\n",
    "            score=h[\"score\"],\n",
    "        )\n",
    "        for h in hits\n",
    "    ]\n",
    "\n",
    "\n",
    "@func(output=\"reranked_hits\")\n",
    "def rerank_hits(\n",
    "    reranker: Reranker,\n",
    "    query: Query,\n",
    "    retrieved: List[RetrievedDoc],\n",
    "    final_top_k: int | None = None,\n",
    ") -> List[RetrievedDoc]:\n",
    "    return reranker.rerank(query, retrieved, top_k=final_top_k)\n",
    "\n",
    "\n",
    "search_pipeline = Pipeline(nodes=[encode_query, retrieve, rerank_hits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de942734",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline(nodes=[encode_and_index, search_pipeline])\n",
    "full_pipeline.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c31af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    Passage(pid=\"p1\", text=\"Hello World\"),\n",
    "    Passage(pid=\"p2\", text=\"Quick Brown Fox\"),\n",
    "]\n",
    "encoder = NumpyRandomEncoder(dim=4)\n",
    "indexer = SimpleIndexer(dim=encoder.dim)\n",
    "\n",
    "outputs = encode_and_index.run(\n",
    "    inputs={\"passage\": corpus, \"encoder\": encoder, \"indexer\": indexer}\n",
    ")\n",
    "index: BaseIndex = outputs[\"index\"]\n",
    "\n",
    "reranker = IdentityReranker()\n",
    "\n",
    "# Single query\n",
    "search_out = search_pipeline.run(\n",
    "    inputs={\n",
    "        \"query\": Query(text=\"hello world\"),\n",
    "        \"encoder\": encoder,\n",
    "        \"index\": index,\n",
    "        \"reranker\": reranker,\n",
    "        \"top_k\": 5,\n",
    "        \"final_top_k\": 3,\n",
    "    }\n",
    ")\n",
    "\n",
    "for doc in search_out[\"reranked_hits\"]:\n",
    "    print(doc.pid, doc.score, doc.text)\n",
    "\n",
    "# ---- Multiple queries ---------------------------------------------------\n",
    "queries = [Query(text=\"hello\"), Query(text=\"quick fox\"), Query(text=\"world\")]\n",
    "batch_out = search_pipeline.map(\n",
    "    inputs={\n",
    "        \"query\": queries,\n",
    "        \"encoder\": encoder,\n",
    "        \"index\": index,\n",
    "        \"reranker\": reranker,\n",
    "        \"top_k\": 5,\n",
    "        \"final_top_k\": 3,\n",
    "    },\n",
    "    map_over=\"query\",\n",
    ")\n",
    "\n",
    "for q, results in zip(queries, batch_out[\"reranked_hits\"]):\n",
    "    print(f\"\\nQuery: {q.text}\")\n",
    "    for r in results:\n",
    "        print(f\"  {r.pid} | {r.score:.3f} | {r.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13cd941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90be693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import (\n",
    "    Dict,\n",
    "    Iterable,\n",
    "    List,\n",
    "    Mapping,\n",
    "    MutableMapping,\n",
    "    Protocol,\n",
    "    Sequence,\n",
    "    Tuple,\n",
    "    TypedDict,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "\n",
    "from daft_func import Pipeline, Subgraph, func, ProgressConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6118e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Core vector type -------------------------------------------------------\n",
    "Vector = npt.NDArray[np.float32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540a4e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Protocols (clear, testable interfaces) --------------------------------\n",
    "class Encoder(Protocol):\n",
    "    \"\"\"Any text encoder that returns a fixed-width embedding.\"\"\"\n",
    "\n",
    "    dim: int\n",
    "\n",
    "    def encode(self, text: str) -> Vector:  # pragma: no cover - external\n",
    "        ...\n",
    "\n",
    "\n",
    "class Indexer(Protocol):\n",
    "    \"\"\"Component that builds/updates an index from encoded passages.\"\"\"\n",
    "\n",
    "    def index(\n",
    "        self, encoded: Sequence[\"EncodedPassage\"]\n",
    "    ) -> \"BaseIndex\":  # pragma: no cover - external\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f906f25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Data models ------------------------------------------------------------\n",
    "@dataclass(frozen=True)\n",
    "class Passage:\n",
    "    pid: str\n",
    "    text: str\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EncodedPassage:\n",
    "    pid: str\n",
    "    text: str\n",
    "    embedding: Vector  # shape: (D,)\n",
    "\n",
    "\n",
    "class SearchHit(TypedDict):\n",
    "    pid: str\n",
    "    score: float\n",
    "\n",
    "\n",
    "class BaseIndex(Protocol):\n",
    "    dim: int\n",
    "\n",
    "    def add(\n",
    "        self, items: Sequence[EncodedPassage]\n",
    "    ) -> None:  # pragma: no cover - example\n",
    "        ...\n",
    "\n",
    "    def search(\n",
    "        self, query_vec: Vector, top_k: int = 10\n",
    "    ) -> List[SearchHit]:  # pragma: no cover - example\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546c755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Simple reference implementations --------------------------------------\n",
    "class NumpyRandomEncoder:\n",
    "    \"\"\"Toy encoder: DO NOT use in production. Demonstrates the interface.\n",
    "\n",
    "    By default it is nondeterministic (np.random). For repeatability in tests,\n",
    "    pass a seeded RNG.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim: int = 4, rng: np.random.Generator | None = None) -> None:\n",
    "        self.dim = dim\n",
    "        self._rng = rng or np.random.default_rng()\n",
    "\n",
    "    def encode(self, text: str) -> Vector:\n",
    "        # In real life: return model.encode(text).astype(np.float32)\n",
    "        return self._rng.random(self.dim, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8012f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InMemoryIndex:\n",
    "    \"\"\"Keeps (pid, original, cleaned, embedding) in RAM.\n",
    "\n",
    "    This illustrates a minimal index that preserves the required triplet\n",
    "    (passage id, original text, embedding) plus the cleaned text.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim: int) -> None:\n",
    "        self.dim = dim\n",
    "        self._data: Dict[str, EncodedPassage] = {}\n",
    "\n",
    "    def add(self, items: Sequence[EncodedPassage]) -> None:\n",
    "        for it in items:\n",
    "            if it.embedding.shape != (self.dim,):\n",
    "                raise ValueError(\n",
    "                    f\"Embedding for {it.pid} has shape {it.embedding.shape}, expected ({self.dim},)\"\n",
    "                )\n",
    "            self._data[it.pid] = it\n",
    "\n",
    "    def search(self, query_vec: Vector, top_k: int = 10) -> List[SearchHit]:\n",
    "        if query_vec.shape != (self.dim,):\n",
    "            raise ValueError(f\"query_vec shape {query_vec.shape} != ({self.dim},)\")\n",
    "        # Cosine similarity\n",
    "        q = query_vec / (np.linalg.norm(query_vec) + 1e-12)\n",
    "        hits: List[Tuple[str, float]] = []\n",
    "        for pid, ep in self._data.items():\n",
    "            v = ep.embedding / (np.linalg.norm(ep.embedding) + 1e-12)\n",
    "            hits.append((pid, float(np.dot(q, v))))\n",
    "        hits.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [{\"pid\": pid, \"score\": score} for pid, score in hits[:top_k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de327d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleIndexer:\n",
    "    \"\"\"Indexer that returns an InMemoryIndex.\"\"\"\n",
    "\n",
    "    def __init__(self, dim: int) -> None:\n",
    "        self.dim = dim\n",
    "\n",
    "    def index(self, encoded: Sequence[EncodedPassage]) -> BaseIndex:\n",
    "        idx = InMemoryIndex(dim=self.dim)\n",
    "        idx.add(encoded)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6085f3a3",
   "metadata": {},
   "source": [
    "## Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48711fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@node(output=\"cleaned_text\")\n",
    "def clean_text(passage: Passage) -> str:\n",
    "    return passage.text.strip().lower()\n",
    "\n",
    "\n",
    "@node(output=\"embedding\")\n",
    "def encode_text(encoder: Encoder, cleaned_text: str) -> Vector:\n",
    "    return encoder.encode(cleaned_text)\n",
    "\n",
    "\n",
    "@node(output=\"encoded_passage\")\n",
    "def pack_encoded(passage: Passage, embedding: Vector) -> EncodedPassage:\n",
    "    return EncodedPassage(pid=passage.pid, text=passage.text, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcf27ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A pipeline that encodes a *single* (pid, text) into an EncodedPassage\n",
    "single_encode = Pipeline(nodes=[clean_text, encode_text])\n",
    "single_encode.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = single_encode.run(\n",
    "    inputs={\"passage\": Passage(pid=\"1\", text=\"hello\"), \"encoder\": Encoder()}\n",
    ")  # should return a dict with keys as output names and corresponding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89c2a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res == {\n",
    "#     \"cleaned_text\": \"hello\",\n",
    "#     \"encoded_text\": np.ndarray([...])\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0135533",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_encode.map(\n",
    "    inputs={\n",
    "        \"passage\": [Passage(pid=\"1\", text=\"hello\"), Passage(pid=\"2\", text=\"world\")],\n",
    "        \"encoder\": Encoder(),\n",
    "    },\n",
    "    map_over=\"passage\",\n",
    ")  # this should return a dict with keys as output names and corresponding lists of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4632da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res == {\n",
    "#     \"cleaned_text\": [\"hello\", \"world\"],\n",
    "#     \"encoded_text\": [\n",
    "#         np.ndarray([...]),  # embedding for \"hello\"\n",
    "#         np.ndarray([...])   # embedding for \"world\"\n",
    "#     ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baf16d1",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8aec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_corpus = Subgraph(\n",
    "    graph=single_encode,\n",
    "    inputs={\"corpus\": \"passage\"},\n",
    "    outputs={\"encoded_passage\": \"encoded_corpus\"},\n",
    "    map_over=\"corpus\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e704fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@node(output=\"index\")\n",
    "def build_index(\n",
    "    indexer: Indexer, encoded_corpus: Sequence[EncodedPassage]\n",
    ") -> BaseIndex:\n",
    "    return indexer.index(encoded_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5c4bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the mapped EncodedPassage list and build an index\n",
    "encode_and_index = Pipeline(functions=[encode_corpus, build_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c4a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy data\n",
    "corpus: List[Passage] = [\n",
    "    Passage(pid=\"p1\", text=\"Hello World\"),\n",
    "    Passage(pid=\"p2\", text=\"The Quick Brown Fox\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db6cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = NumpyRandomEncoder(dim=4)\n",
    "indexer = SimpleIndexer(dim=encoder.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cbc502",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_and_index.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1ac359",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = encode_and_index.run(\n",
    "    inputs={\n",
    "        \"corpus\": corpus,\n",
    "        \"encoder\": encoder,\n",
    "        \"indexer\": indexer,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95095fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index: BaseIndex = outputs[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed61c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Retrieval + Reranking --------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc02c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "@func(output=\"retrieved\")\n",
    "def retrieve(\n",
    "    index: BaseIndex, query_vec: Vector, top_k: int = 10\n",
    ") -> List[RetrievedDoc]:\n",
    "    return [\n",
    "        RetrievedDoc(\n",
    "            pid=h[\"pid\"],\n",
    "            text=index.get(h[\"pid\"]).text,\n",
    "            embedding=index.get(h[\"pid\"]).embedding,\n",
    "            score=h[\"score\"],\n",
    "        )\n",
    "        for h in hits\n",
    "    ]\n",
    "\n",
    "\n",
    "@func(output=\"reranked_hits\")\n",
    "def rerank_hits(\n",
    "    reranker: Reranker,\n",
    "    query: Query,\n",
    "    retrieved: List[RetrievedDoc],\n",
    "    final_top_k: int | None = None,\n",
    ") -> List[RetrievedDoc]:\n",
    "    return reranker.rerank(query, retrieved, top_k=final_top_k)\n",
    "\n",
    "\n",
    "search_pipeline = Pipeline(nodes=[encode_query, retrieve, rerank_hits])\n",
    "search_pipeline.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15da15e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Example usage ----------------------------------------------------------\n",
    "corpus = [\n",
    "    Passage(pid=\"p1\", text=\"Hello World\"),\n",
    "    Passage(pid=\"p2\", text=\"Quick Brown Fox\"),\n",
    "]\n",
    "encoder = NumpyRandomEncoder(dim=4)\n",
    "indexer = SimpleIndexer(dim=encoder.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cbff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = encode_and_index.run(\n",
    "    inputs={\"passage\": corpus, \"encoder\": encoder, \"indexer\": indexer}\n",
    ")\n",
    "index: BaseIndex = outputs[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bf244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker = IdentityReranker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998aead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single query\n",
    "search_out = search_pipeline.run(\n",
    "    inputs={\n",
    "        \"query\": Query(text=\"hello world\"),\n",
    "        \"encoder\": encoder,\n",
    "        \"index\": index,\n",
    "        \"reranker\": reranker,\n",
    "        \"top_k\": 5,\n",
    "        \"final_top_k\": 3,\n",
    "    }\n",
    ")\n",
    "\n",
    "for doc in search_out[\"reranked_hits\"]:\n",
    "    print(doc.pid, doc.score, doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5827138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Multiple queries ---------------------------------------------------\n",
    "queries = [Query(text=\"hello\"), Query(text=\"quick fox\"), Query(text=\"world\")]\n",
    "batch_out = search_pipeline.map(\n",
    "    inputs={\n",
    "        \"query\": queries,\n",
    "        \"encoder\": encoder,\n",
    "        \"index\": index,\n",
    "        \"reranker\": reranker,\n",
    "        \"top_k\": 5,\n",
    "        \"final_top_k\": 3,\n",
    "    },\n",
    "    map_over=\"query\",\n",
    ")\n",
    "\n",
    "\n",
    "for q, results in zip(queries, batch_out[\"reranked_hits\"]):\n",
    "    print(f\" {r.pid} | {r.score:.3f} | {r.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c44919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4e686f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0bd536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "from daft_func import Pipeline, Runner, func\n",
    "from examples.retrieval import (\n",
    "    IdentityReranker,\n",
    "    Query,\n",
    "    RerankedHit,\n",
    "    Reranker,\n",
    "    RetrievalResult,\n",
    "    Retriever,\n",
    "    ToyRetriever,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e09e74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from daft_func import ProgressConfig\n",
    "\n",
    "# Custom configuration\n",
    "progress_config = ProgressConfig(enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3007676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self):\n",
    "        self.dim = 4\n",
    "\n",
    "    def encode(self, text: str) -> np.ndarray:\n",
    "        return np.array(np.random.rand(self.dim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ba58cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"svg-container\" style=\"max-width: 100%;\"><?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 13.1.2 (20250808.2320)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"268pt\" height=\"234pt\"\n",
       " viewBox=\"0.00 0.00 268.00 234.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 229.5)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-229.5 263.88,-229.5 263.88,4 -4,4\"/>\n",
       "<!-- 4994406288 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>4994406288</title>\n",
       "<path fill=\"#87ceeb\" stroke=\"black\" d=\"M247.88,-142.25C247.88,-142.25 150.38,-142.25 150.38,-142.25 144.38,-142.25 138.38,-136.25 138.38,-130.25 138.38,-130.25 138.38,-106.75 138.38,-106.75 138.38,-100.75 144.38,-94.75 150.38,-94.75 150.38,-94.75 247.88,-94.75 247.88,-94.75 253.88,-94.75 259.88,-100.75 259.88,-106.75 259.88,-106.75 259.88,-130.25 259.88,-130.25 259.88,-136.25 253.88,-142.25 247.88,-142.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"169.88\" y=\"-123.85\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"12.00\">clean_text</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"150.38\" y=\"-105.1\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"12.00\">cleaned_text</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"223.12\" y=\"-105.1\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\"> &#160;: </text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"235.12\" y=\"-105.1\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"12.00\">str</text>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"146.38,-118.5 146.38,-118.5 251.88,-118.5 251.88,-118.5 146.38,-118.5\"/>\n",
       "</g>\n",
       "<!-- 4994402400 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>4994402400</title>\n",
       "<path fill=\"#87ceeb\" stroke=\"black\" d=\"M154.38,-47.5C154.38,-47.5 23.87,-47.5 23.87,-47.5 17.87,-47.5 11.88,-41.5 11.88,-35.5 11.88,-35.5 11.88,-12 11.88,-12 11.88,-6 17.88,0 23.88,0 23.88,0 154.38,0 154.38,0 160.38,0 166.38,-6 166.38,-12 166.38,-12 166.38,-35.5 166.38,-35.5 166.38,-41.5 160.38,-47.5 154.38,-47.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"53.88\" y=\"-29.1\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"12.00\">encode_text</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"23.88\" y=\"-10.35\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"12.00\">encoded_text</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"101.88\" y=\"-10.35\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\"> &#160;: </text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"113.88\" y=\"-10.35\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"12.00\">ndarray</text>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"19.88,-23.75 19.88,-23.75 158.38,-23.75 158.38,-23.75 19.88,-23.75\"/>\n",
       "</g>\n",
       "<!-- 4994406288&#45;&gt;4994402400 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>4994406288&#45;&gt;4994402400</title>\n",
       "<path fill=\"none\" stroke=\"#87ceeb\" d=\"M171.65,-94.33C157.61,-82.49 140.34,-67.93 125.23,-55.2\"/>\n",
       "<polygon fill=\"#87ceeb\" stroke=\"#87ceeb\" points=\"127.69,-52.69 117.79,-48.92 123.18,-58.04 127.69,-52.69\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"178.46\" y=\"-67.25\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"transparent\">cleaned_text</text>\n",
       "</g>\n",
       "<!-- 4345712448 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>4345712448</title>\n",
       "<polygon fill=\"#90ee90\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"230,-225.5 168.25,-225.5 168.25,-189.5 230,-189.5 230,-225.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"176.25\" y=\"-203.47\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"12.00\">text</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"197.25\" y=\"-203.47\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\"> &#160;: </text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"209.25\" y=\"-203.47\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"12.00\">str</text>\n",
       "</g>\n",
       "<!-- 4345712448&#45;&gt;4994406288 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>4345712448&#45;&gt;4994406288</title>\n",
       "<path fill=\"none\" stroke=\"#90ee90\" d=\"M199.12,-189.31C199.12,-179.18 199.12,-166 199.12,-153.82\"/>\n",
       "<polygon fill=\"#90ee90\" stroke=\"#90ee90\" points=\"202.63,-154.1 199.13,-144.1 195.63,-154.1 202.63,-154.1\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"207.38\" y=\"-162\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"transparent\">text</text>\n",
       "</g>\n",
       "<!-- 4345302336 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>4345302336</title>\n",
       "<polygon fill=\"#90ee90\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"120.25,-136.5 0,-136.5 0,-100.5 120.25,-100.5 120.25,-136.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"8\" y=\"-114.47\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"12.00\">encoder</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"55.25\" y=\"-114.47\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\"> &#160;: </text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"67.25\" y=\"-114.47\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"12.00\">Encoder</text>\n",
       "</g>\n",
       "<!-- 4345302336&#45;&gt;4994402400 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>4345302336&#45;&gt;4994402400</title>\n",
       "<path fill=\"none\" stroke=\"#90ee90\" d=\"M65.58,-100.05C69.23,-88.38 74.16,-72.63 78.56,-58.55\"/>\n",
       "<polygon fill=\"#90ee90\" stroke=\"#90ee90\" points=\"81.85,-59.76 81.49,-49.17 75.16,-57.67 81.85,-59.76\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"93.61\" y=\"-67.25\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"transparent\">encoder</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n",
       "</div><style>#svg-container svg {max-width: 100%; height: auto;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "@func(output=\"cleaned_text\")\n",
    "def clean_text(text: str) -> str:\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "@func(output=\"encoded_text\")\n",
    "def encode_text(encoder: Encoder, cleaned_text: str) -> np.ndarray:\n",
    "    return encoder.encode(cleaned_text)\n",
    "\n",
    "\n",
    "encoding_pipeline = Pipeline(\n",
    "    functions=[clean_text, encode_text],\n",
    ")\n",
    "encoding_pipeline.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e501bccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23f40f74f524752b0a1aeeda55ec21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "⏸ cleaned_text:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff915c1abd64929a441149df855eef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "⏸ encoded_text:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = encoding_pipeline.run(inputs={\"text\": \"hello\", \"encoder\": Encoder()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "582e821d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13542552, 0.56111283, 0.64619301, 0.57526549])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"encoded_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411fa81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res == {\n",
    "#     \"cleaned_text\": \"hello\",\n",
    "#     \"encoded_text\": np.ndarray([...])  # shape (4,)\n",
    "# }\n",
    "\n",
    "# res[\"encoded_text\"]  # → a single 1‑D embedding vector, e.g. array([0.12, 0.34, 0.56, 0.78])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f54bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = encoding_pipeline.map(inputs={\"text\": [\"hello\", \"world\"], \"encoder\": Encoder()}, map_axis=\"text\") # this should work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9748dd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res == {\n",
    "#     \"cleaned_text\": [\"hello\", \"world\"],\n",
    "#     \"encoded_text\": [\n",
    "#         np.ndarray([...]),  # embedding for \"hello\"\n",
    "#         np.ndarray([...])   # embedding for \"world\"\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# res[\"encoded_text\"]  # → list of two vectors, each shape (4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a3e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Indexer:\n",
    "    def index(self, encoded_corpus: ?) -> str:\n",
    "        return encoded_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def40b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@func(output=\"index\")\n",
    "def index(indexer: Indexer, encoded_corpus: Dict[str, str], test: bool = True) -> str:\n",
    "    return indexer.index(encoded_corpus)\n",
    "\n",
    "\n",
    "indexing_pipeline = Pipeline(functions=[index])\n",
    "indexing_pipeline.visualize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75e986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing_pipeline.run(\n",
    "    inputs={\"corpus\": [..., ...], \"encoder\": Encoder(), \"indexer\": Indexer()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e905423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_passages = Subgraph(\n",
    "    graph=encoding_pipeline,  # or a single @func\n",
    "    inputs={\"corpus\": \"text\"},  # external → internal\n",
    "    outputs={\"encoded_text\": \"encoded_corpus\"},  # internal → external\n",
    "    map_over=\"corpus\",\n",
    ")\n",
    "\n",
    "encoding_indexing_pipeline = Pipeline(functions=[encode_passages, index])\n",
    "encoding_indexing_pipeline.visualize()  # should show the encode_passages step (with pipeline icon/color) and then index + save_index steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c112ef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_indexing_pipeline.run(\n",
    "    inputs={\"corpus\": [..., ...], \"encoder\": Encoder(), \"indexer\": Indexer()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ec33fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@func(output=\"hits\")\n",
    "def retrieve(\n",
    "    retriever: Retriever, query: Query, top_k: int, index: str\n",
    ") -> RetrievalResult:\n",
    "    return retriever.retrieve(index, query, top_k=top_k)\n",
    "\n",
    "\n",
    "@func(output=\"reranked_hits\")\n",
    "def rerank(\n",
    "    reranker: Reranker, query: Query, hits: RetrievalResult, top_k: int\n",
    ") -> List[RerankedHit]:\n",
    "    return reranker.rerank(query, hits, top_k=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98b335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(functions=[retrieve, rerank])\n",
    "pipeline.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c23c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.run(inputs={\"query\": [..., ...], \"top_k\": 2, \"index\": \"...\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8a2ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or\n",
    "pipeline = Pipeline(functions=[indexing_pipeline, retrieve, rerank], map_axis=\"query\")\n",
    "pipeline.run(inputs={\"query\": [..., ...], \"top_k\": 2, \"corpus\": \"...\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c879a098",
   "metadata": {},
   "source": [
    "questions/comments:\n",
    "1. does it make sense to cache the corpus? to me it makes sense to avoid recomputation....... what is the cost of that? is it doable?\n",
    "2. when .visualizing, only show by default zero or one (depending on how you count) level in. so within the indexing pipeline I should be seeing just one step for the encode_passages instead of seeing the internal pipeline. if level=2 then I'll see a box that says encode_passages and within it the pipeline. if level=2 and unwrap or flat=True then I'll just see the pipeline somehow in a way that maps the multi inputs to the specific inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c88d82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@func(output=\"index_path\", cache=True)\n",
    "def index(retriever: Retriever, corpus: Dict[str, str], test: bool = True) -> str:\n",
    "    index_path = retriever.index(corpus)\n",
    "    return index_path\n",
    "\n",
    "\n",
    "@func(output=\"hits\", map_axis=\"query\", key_attr=\"query_uuid\", cache=True)\n",
    "def retrieve(\n",
    "    retriever: Retriever, query: Query, top_k: int, index_path: str\n",
    ") -> RetrievalResult:\n",
    "    return retriever.retrieve(index_path, query, top_k=top_k)\n",
    "\n",
    "\n",
    "@func(output=\"reranked_hits\", map_axis=\"query\", key_attr=\"query_uuid\", cache=True)\n",
    "def rerank(\n",
    "    reranker: Reranker, query: Query, hits: RetrievalResult, top_k: int\n",
    ") -> List[RerankedHit]:\n",
    "    return reranker.rerank(query, hits, top_k=top_k)\n",
    "\n",
    "\n",
    "pipeline = Pipeline(functions=[index, retrieve, rerank])\n",
    "pipeline.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58371905",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {\n",
    "    \"d1\": \"a quick brown fox jumps\",\n",
    "    \"d2\": \"brown dog sleeps\",\n",
    "    \"d3\": \"five boxing wizards jump quickly\",\n",
    "}\n",
    "\n",
    "single_inputs = {\n",
    "    \"retriever\": ToyRetriever(),\n",
    "    \"corpus\": corpus,\n",
    "    \"reranker\": IdentityReranker(),\n",
    "    \"query\": Query(query_uuid=\"q1\", text=\"quick brown\"),\n",
    "    \"top_k\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d245fc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from daft_func import CacheConfig\n",
    "\n",
    "# Create runner with auto mode (chooses based on batch size)\n",
    "runner = Runner(\n",
    "    mode=\"local\",\n",
    "    batch_threshold=2,\n",
    "    # cache_config=CacheConfig(enabled=True),  # , backend=DiskCache(cache_dir=\".cache\")),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2946ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from daft_func import Pipeline, ProgressConfig, Runner, func\n",
    "\n",
    "# Custom configuration\n",
    "progress_config = ProgressConfig(\n",
    "    enabled=True,\n",
    "    theme=\"dark\",  # or \"light\", or None for auto\n",
    "    # show_cache_indicators=True,\n",
    "    # show_timing=True,\n",
    ")\n",
    "runner = Runner(progress_config=progress_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b36a6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294cd9de878c4b1ba61a0b23f72db9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "⏸ index_path   :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7777f0782a6b467698f9bb7aea1b58f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "⏸ hits         :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac0deef1b4149c5884e1bdb03f0ade6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "⏸ reranked_hits:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = runner.run(inputs=single_inputs)  # should show misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14dd1009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".cell-output-ipywidget-background {\n",
       "    background-color: transparent !important;\n",
       "}\n",
       ":root {\n",
       "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
       "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
       "}  \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0808a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_inputs = {\n",
    "    \"corpus\": corpus,\n",
    "    \"retriever\": ToyRetriever(),\n",
    "    \"reranker\": IdentityReranker(),\n",
    "    \"query\": [\n",
    "        Query(query_uuid=\"q1\", text=\"quick brown\"),\n",
    "        Query(query_uuid=\"q2\", text=\"wizards jump\"),\n",
    "        Query(query_uuid=\"q3\", text=\"brown dog\"),\n",
    "    ],\n",
    "    \"top_k\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0dda9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0260c8a98636405885bbca70cb1fc765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "⏸ index_path   :   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31e22c55c5d41b381e4a6da28abd926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "⏸ hits         :   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e8c47d18e84df9b8050dfc176854a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "⏸ reranked_hits:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = runner.run(inputs=multi_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2edea3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d67d38f46d947d594757545710000b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "⏸ index_path   :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa9073fcff24325ae9d746cd60d0062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "⏸ hits         :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40b1370e53f441485a2f9635a8c2cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "⏸ reranked_hits:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = runner.run(inputs=single_inputs)  # should show misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "657621e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {\n",
    "    \"d1\": \"a quick brown fox jumps\",\n",
    "    \"d2\": \"brown dog sleeps\",\n",
    "    \"d3\": \"five boxing wizards jump quickly\",\n",
    "}\n",
    "\n",
    "single_inputs = {\n",
    "    \"retriever\": ToyRetriever(),\n",
    "    \"corpus\": corpus,\n",
    "    \"reranker\": IdentityReranker(),\n",
    "    \"query\": Query(query_uuid=\"q1\", text=\"quick brown\"),\n",
    "    \"top_k\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e055796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fac41d5e19d4e328a4b6d765298b67d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "⏸ index_path   :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3e2d81da0e45e3801626dd29d17f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "⏸ hits         :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef86345d2cb432c8880d4137abfa789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "⏸ reranked_hits:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = runner.run(inputs=single_inputs)  # should show hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0d23029",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {\n",
    "    \"d1\": \"a quick brown fox jumps\",\n",
    "    \"d2\": \"brown dog sleeps\",\n",
    "    \"d3\": \"five boxing wizards jump quickly\",\n",
    "}\n",
    "\n",
    "single_inputs = {\n",
    "    \"retriever\": ToyRetriever(),\n",
    "    \"corpus\": corpus,\n",
    "    \"reranker\": IdentityReranker(),\n",
    "    \"query\": Query(query_uuid=\"q1\", text=\"quick brown\"),\n",
    "    \"top_k\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc43b1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a468acc2444ea9b8f631ae3436583d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "⏸ index_path   :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c833f45844425fb2f9dae8a266773e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "⏸ hits         :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218f6fbe0fc04c9a8f922fb2e7c7f151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "⏸ reranked_hits:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = runner.run(\n",
    "    inputs=single_inputs\n",
    ")  # should show hits, but showing misses, probably because of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13492948",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_inputs = {\n",
    "    \"corpus\": corpus,\n",
    "    \"retriever\": ToyRetriever(),\n",
    "    \"reranker\": IdentityReranker(),\n",
    "    \"query\": [\n",
    "        Query(query_uuid=\"q1\", text=\"quick brown\"),\n",
    "        Query(query_uuid=\"q2\", text=\"wizards jump\"),\n",
    "        Query(query_uuid=\"q3\", text=\"brown dog\"),\n",
    "    ],\n",
    "    \"top_k\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5da4672b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b70ccd7bbaf44299b48017c5b4adeb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "⏸ index_path   :   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1c3d0d481443d29f8de0f21c6a6cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "⏸ hits         :   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660e1c81bed044ae982169d819584868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "⏸ reranked_hits:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = runner.run(inputs=multi_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef16daa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[RerankedHit(query_uuid='q1', doc_id='d1', score=2.0),\n",
       "  RerankedHit(query_uuid='q1', doc_id='d2', score=1.0)],\n",
       " [RerankedHit(query_uuid='q2', doc_id='d3', score=2.0),\n",
       "  RerankedHit(query_uuid='q2', doc_id='d1', score=1.0)],\n",
       " [RerankedHit(query_uuid='q3', doc_id='d2', score=2.0),\n",
       "  RerankedHit(query_uuid='q3', doc_id='d1', score=1.0)]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"reranked_hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5cf2e86",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CacheConfig.__init__() got an unexpected keyword argument 'cache_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mlocal\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdaft\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m      2\u001b[39m     runner = Runner(\n\u001b[32m      3\u001b[39m         pipeline=pipeline,\n\u001b[32m      4\u001b[39m         mode=mode,\n\u001b[32m      5\u001b[39m         batch_threshold=\u001b[32m2\u001b[39m,\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m         cache_config=\u001b[43mCacheConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43menabled\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.cache\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[32m      7\u001b[39m     )\n\u001b[32m      8\u001b[39m     result = runner.run(inputs=multi_inputs)\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     10\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode.upper()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m5s\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(result[\u001b[33m'\u001b[39m\u001b[33mreranked_hits\u001b[39m\u001b[33m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m queries processed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m     )\n",
      "\u001b[31mTypeError\u001b[39m: CacheConfig.__init__() got an unexpected keyword argument 'cache_dir'"
     ]
    }
   ],
   "source": [
    "for mode in [\"local\", \"daft\", \"auto\"]:\n",
    "    runner = Runner(\n",
    "        mode=mode,\n",
    "        batch_threshold=2,\n",
    "        cache_config=CacheConfig(enabled=True, cache_dir=\".cache\"),\n",
    "    )\n",
    "    result = runner.run(pipeline, inputs=multi_inputs)\n",
    "    print(\n",
    "        f\"✅ {mode.upper():5s} mode: {len(result['reranked_hits'])} queries processed\"\n",
    "    )\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"🎉 Demo complete!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2cdce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CACHE] embeddings: ✗ MISS (6.01s) | result: ✗ MISS (2.01s)\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "from daft_func import func\n",
    "\n",
    "\n",
    "@func(output=\"embeddings\", cache=True, cache_key=\"model_v1\")\n",
    "def encode(text: str) -> list:\n",
    "    sleep(6)\n",
    "    return \"s\"\n",
    "\n",
    "\n",
    "@func(output=\"result\", cache=True)\n",
    "def process(embeddings: list, threshold: float) -> dict:\n",
    "    sleep(2)\n",
    "    return \"t\"\n",
    "\n",
    "\n",
    "pipeline = Pipeline(functions=[encode, process])\n",
    "cache_config = CacheConfig(enabled=True, cache_dir=\".cache\")\n",
    "runner = Runner(cache_config=cache_config)\n",
    "# First run: executes both\n",
    "result1 = runner.run(pipeline, inputs={\"text\": \"hello\", \"threshold\": 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3402c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Second run, change threshold: encode cached, process re-executes\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m result2 = \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhello\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreshold\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/daft-func/src/daft_func/runner.py:124\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    121\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._run_local_loop(inputs, map_axis)\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    123\u001b[39m     \u001b[38;5;66;03m# True single item execution\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# Print cache summary if enabled\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._cache_stats:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/daft-func/src/daft_func/runner.py:203\u001b[39m, in \u001b[36mRunner._run_single\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;66;03m# Cache miss or failed to load - execute node\u001b[39;00m\n\u001b[32m    202\u001b[39m start_time = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m res = \u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m execution_time = time.time() - start_time\n\u001b[32m    205\u001b[39m outputs[node.meta.output_name] = res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/daft-func/src/daft_func/decorator.py:45\u001b[39m, in \u001b[36mfunc.<locals>.deco.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mprocess\u001b[39m\u001b[34m(embeddings, threshold)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;129m@func\u001b[39m(output=\u001b[33m\"\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m\"\u001b[39m, cache=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess\u001b[39m(embeddings: \u001b[38;5;28mlist\u001b[39m, threshold: \u001b[38;5;28mfloat\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mt\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Second run, change threshold: encode cached, process re-executes\n",
    "result2 = runner.run(inputs={\"text\": \"hello\", \"threshold\": 0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c40a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from daft_func import Pipeline, func\n",
    "\n",
    "\n",
    "# Define a simple pipeline\n",
    "@func(output=\"doubled\")\n",
    "def double(x: int) -> int:\n",
    "    \"\"\"Double the input value.\"\"\"\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "@func(output=\"result\")\n",
    "def add_value(doubled: int, offset: int = 5) -> int:\n",
    "    \"\"\"Add an offset to the doubled value.\"\"\"\n",
    "    return doubled + offset\n",
    "\n",
    "\n",
    "# Create pipeline with explicit functions\n",
    "pipeline = Pipeline(functions=[double, add_value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366d36b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"svg-container\" style=\"max-width: 100%;\"><?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 13.1.2 (20250808.2320)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"218pt\" height=\"211pt\"\n",
       " viewBox=\"0.00 0.00 218.00 211.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 207)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-207 213.75,-207 213.75,4 -4,4\"/>\n",
       "<!-- 4573658528 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>4573658528</title>\n",
       "<path fill=\"#87ceeb\" stroke=\"black\" d=\"M197.75,-131C197.75,-131 125.75,-131 125.75,-131 119.75,-131 113.75,-125 113.75,-119 113.75,-119 113.75,-95.5 113.75,-95.5 113.75,-89.5 119.75,-83.5 125.75,-83.5 125.75,-83.5 197.75,-83.5 197.75,-83.5 203.75,-83.5 209.75,-89.5 209.75,-95.5 209.75,-95.5 209.75,-119 209.75,-119 209.75,-125 203.75,-131 197.75,-131\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"141.88\" y=\"-112.6\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"12.00\">double</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"125.75\" y=\"-93.85\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"12.00\">doubled</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"173\" y=\"-93.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\"> &#160;: </text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"185\" y=\"-93.85\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"12.00\">int</text>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"121.75,-107.25 121.75,-107.25 201.75,-107.25 201.75,-107.25 121.75,-107.25\"/>\n",
       "</g>\n",
       "<!-- 4573658624 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>4573658624</title>\n",
       "<path fill=\"#87ceeb\" stroke=\"black\" d=\"M134.38,-47.5C134.38,-47.5 75.12,-47.5 75.12,-47.5 69.12,-47.5 63.12,-41.5 63.12,-35.5 63.12,-35.5 63.12,-12 63.12,-12 63.12,-6 69.12,0 75.12,0 75.12,0 134.38,0 134.38,0 140.38,0 146.38,-6 146.38,-12 146.38,-12 146.38,-35.5 146.38,-35.5 146.38,-41.5 140.38,-47.5 134.38,-47.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"75.12\" y=\"-29.1\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"12.00\">add_value</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"76.25\" y=\"-10.35\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"12.00\">result</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"108.5\" y=\"-10.35\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\"> &#160;: </text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"120.5\" y=\"-10.35\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"12.00\">int</text>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"71.12,-23.75 71.12,-23.75 138.38,-23.75 138.38,-23.75 71.12,-23.75\"/>\n",
       "</g>\n",
       "<!-- 4573658528&#45;&gt;4573658624 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>4573658528&#45;&gt;4573658624</title>\n",
       "<path fill=\"none\" stroke=\"#87ceeb\" d=\"M145.57,-83.11C139.97,-75.11 133.59,-65.99 127.57,-57.37\"/>\n",
       "<polygon fill=\"#87ceeb\" stroke=\"#87ceeb\" points=\"130.44,-55.37 121.84,-49.18 124.7,-59.39 130.44,-55.37\"/>\n",
       "</g>\n",
       "<!-- 4417908200 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>4417908200</title>\n",
       "<polygon fill=\"#90ee90\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"188.75,-203 134.75,-203 134.75,-167 188.75,-167 188.75,-203\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"146\" y=\"-180.97\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"12.00\">x</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"152.75\" y=\"-180.97\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\"> &#160;: </text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"164.75\" y=\"-180.97\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"12.00\">int</text>\n",
       "</g>\n",
       "<!-- 4417908200&#45;&gt;4573658528 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>4417908200&#45;&gt;4573658528</title>\n",
       "<path fill=\"none\" stroke=\"#90ee90\" d=\"M161.75,-166.81C161.75,-159.69 161.75,-151.16 161.75,-142.85\"/>\n",
       "<polygon fill=\"#90ee90\" stroke=\"#90ee90\" points=\"165.25,-142.92 161.75,-132.92 158.25,-142.92 165.25,-142.92\"/>\n",
       "</g>\n",
       "<!-- 4417893480 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>4417893480</title>\n",
       "<polygon fill=\"#90ee90\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"95.5,-125.25 0,-125.25 0,-89.25 95.5,-89.25 95.5,-125.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"8\" y=\"-103.22\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"12.00\">offset</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"40.25\" y=\"-103.22\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\"> &#160;: </text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"52.25\" y=\"-103.22\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"12.00\">int</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"65\" y=\"-103.22\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\"> &#160;= 5</text>\n",
       "</g>\n",
       "<!-- 4417893480&#45;&gt;4573658624 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>4417893480&#45;&gt;4573658624</title>\n",
       "<path fill=\"none\" stroke=\"#90ee90\" d=\"M59.84,-88.97C66.31,-79.71 74.49,-68.01 82.09,-57.14\"/>\n",
       "<polygon fill=\"#90ee90\" stroke=\"#90ee90\" points=\"84.84,-59.33 87.7,-49.13 79.1,-55.32 84.84,-59.33\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n",
       "</div><style>#svg-container svg {max-width: 100%; height: auto;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and display visualization\n",
    "pipeline.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e201764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "from daft_func import Runner, func\n",
    "\n",
    "\n",
    "# 1. Define your data models\n",
    "class Query(BaseModel):\n",
    "    id: str\n",
    "    text: str\n",
    "\n",
    "\n",
    "class Result(BaseModel):\n",
    "    id: str\n",
    "    score: float\n",
    "\n",
    "\n",
    "@func(output=\"results\", map_axis=\"query\", key_attr=\"id\")\n",
    "def process(query: Query, threshold: float) -> Result:\n",
    "    score = len(query.text) * threshold\n",
    "    return Result(id=query.id, score=score)\n",
    "\n",
    "\n",
    "# 3. Create pipeline and runner\n",
    "pipeline = Pipeline(functions=[process])\n",
    "runner = Runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae997cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Result(id='q1', score=2.5)]\n"
     ]
    }
   ],
   "source": [
    "outputs = runner.run(\n",
    "    inputs={\n",
    "        \"query\": [Query(id=\"q1\", text=\"hello\")],\n",
    "        \"threshold\": 0.5,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(outputs[\"results\"])\n",
    "# [Result(id='q1', score=2.5), Result(id='q2', score=2.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad04a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Result(id='q1', score=2.5), Result(id='q2', score=2.5)]\n"
     ]
    }
   ],
   "source": [
    "outputs = runner.run(\n",
    "    inputs={\n",
    "        \"query\": [\n",
    "            Query(id=\"q1\", text=\"hello\"),\n",
    "            Query(id=\"q2\", text=\"world\"),\n",
    "        ],\n",
    "        \"threshold\": 0.5,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(outputs[\"results\"])\n",
    "# [Result(id='q1', score=2.5), Result(id='q2', score=2.5)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daft-func",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
