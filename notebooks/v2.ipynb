{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac793889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import (\n",
    "    Dict,\n",
    "    List,\n",
    "    Protocol,\n",
    "    Sequence,\n",
    "    Tuple,\n",
    "    TypedDict,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "\n",
    "from daft_func import NestedPipeline, Pipeline, func\n",
    "\n",
    "# ---- Core vector type -------------------------------------------------------\n",
    "Vector = npt.NDArray[np.float32]\n",
    "\n",
    "\n",
    "# ---- Protocols -------------------------------------------------------------\n",
    "class Encoder(Protocol):\n",
    "    dim: int\n",
    "\n",
    "    def encode(self, text: str) -> Vector: ...\n",
    "\n",
    "\n",
    "class Indexer(Protocol):\n",
    "    def index(self, encoded: Sequence[\"EncodedPassage\"]) -> \"BaseIndex\": ...\n",
    "\n",
    "\n",
    "class Reranker(Protocol):\n",
    "    def rerank(\n",
    "        self, query: \"Query\", hits: Sequence[\"RetrievedDoc\"], top_k: int | None = None\n",
    "    ) -> List[\"RetrievedDoc\"]: ...\n",
    "\n",
    "\n",
    "# ---- Data models ------------------------------------------------------------\n",
    "@dataclass(frozen=True)\n",
    "class Passage:\n",
    "    pid: str\n",
    "    text: str\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EncodedPassage:\n",
    "    pid: str\n",
    "    text: str\n",
    "    embedding: Vector\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Query:\n",
    "    text: str\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class RetrievedDoc:\n",
    "    pid: str\n",
    "    text: str\n",
    "    embedding: Vector\n",
    "    score: float\n",
    "\n",
    "\n",
    "class SearchHit(TypedDict):\n",
    "    pid: str\n",
    "    score: float\n",
    "\n",
    "\n",
    "class BaseIndex(Protocol):\n",
    "    dim: int\n",
    "\n",
    "    def add(self, items: Sequence[EncodedPassage]) -> None: ...\n",
    "    def search(self, query_vec: Vector, top_k: int = 10) -> List[SearchHit]: ...\n",
    "    def get(self, pid: str) -> EncodedPassage: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd68ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Implementations -------------------------------------------------------\n",
    "class NumpyRandomEncoder:\n",
    "    def __init__(self, dim: int = 4, rng: np.random.Generator | None = None) -> None:\n",
    "        self.dim = dim\n",
    "        self._rng = rng or np.random.default_rng()\n",
    "\n",
    "    def encode(self, text: str) -> Vector:\n",
    "        return self._rng.random(self.dim, dtype=np.float32)\n",
    "\n",
    "\n",
    "class InMemoryIndex:\n",
    "    def __init__(self, dim: int) -> None:\n",
    "        self.dim = dim\n",
    "        self._data: Dict[str, EncodedPassage] = {}\n",
    "\n",
    "    def add(self, items: Sequence[EncodedPassage]) -> None:\n",
    "        for it in items:\n",
    "            self._data[it.pid] = it\n",
    "\n",
    "    def search(self, query_vec: Vector, top_k: int = 10) -> List[SearchHit]:\n",
    "        q = query_vec / (np.linalg.norm(query_vec) + 1e-12)\n",
    "        hits: List[Tuple[str, float]] = []\n",
    "        for pid, ep in self._data.items():\n",
    "            v = ep.embedding / (np.linalg.norm(ep.embedding) + 1e-12)\n",
    "            hits.append((pid, float(np.dot(q, v))))\n",
    "        hits.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [{\"pid\": pid, \"score\": score} for pid, score in hits[:top_k]]\n",
    "\n",
    "    def get(self, pid: str) -> EncodedPassage:\n",
    "        return self._data[pid]\n",
    "\n",
    "\n",
    "class SimpleIndexer:\n",
    "    def __init__(self, dim: int) -> None:\n",
    "        self.dim = dim\n",
    "\n",
    "    def index(self, encoded: Sequence[EncodedPassage]) -> BaseIndex:\n",
    "        idx = InMemoryIndex(self.dim)\n",
    "        idx.add(encoded)\n",
    "        return idx\n",
    "\n",
    "\n",
    "class IdentityReranker:\n",
    "    def rerank(\n",
    "        self, query: Query, hits: Sequence[RetrievedDoc], top_k: int | None = None\n",
    "    ) -> List[RetrievedDoc]:\n",
    "        out = list(hits)\n",
    "        if top_k is not None:\n",
    "            out = out[:top_k]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73437cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Encode Pipeline ---------------------------------------------\n",
    "@func(output=\"cleaned_text\")\n",
    "def clean_text(passage: Passage) -> str:\n",
    "    return passage.text.strip().lower()\n",
    "\n",
    "\n",
    "@func(output=\"embedding\")\n",
    "def encode_text(encoder: Encoder, cleaned_text: str, is_query: bool = False) -> Vector:\n",
    "    return encoder.encode(cleaned_text, is_query)\n",
    "\n",
    "\n",
    "@func(output=\"encoded_passage\")\n",
    "def pack_encoded(passage: Passage, embedding: Vector) -> EncodedPassage:\n",
    "    return EncodedPassage(pid=passage.pid, text=passage.text, embedding=embedding)\n",
    "\n",
    "\n",
    "single_encode = Pipeline(functions=[clean_text, encode_text, pack_encoded])\n",
    "single_encode.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6986ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = single_encode.run(\n",
    "    inputs={\"passage\": Passage(pid=\"1\", text=\"hello\"), \"encoder\": Encoder()}\n",
    ")  # should return a dict with keys as output names and corresponding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8dd50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res == {\n",
    "#     \"cleaned_text\": \"hello\",\n",
    "#     \"encoded_text\": np.ndarray([...])\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6856035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_encode.map(\n",
    "    inputs={\n",
    "        \"passage\": [Passage(pid=\"1\", text=\"hello\"), Passage(pid=\"2\", text=\"world\")],\n",
    "        \"encoder\": Encoder(),\n",
    "    },\n",
    "    map_over=\"passage\",\n",
    ")  # this should return a dict with keys as output names and corresponding lists of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15ffb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res == {\n",
    "#     \"cleaned_text\": [\"hello\", \"world\"],\n",
    "#     \"encoded_text\": [\n",
    "#         np.ndarray([...]),  # embedding for \"hello\"\n",
    "#         np.ndarray([...])   # embedding for \"world\"\n",
    "#     ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9edef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Index\n",
    "encode_corpus = NestedPipeline(\n",
    "    pipeline=single_encode,\n",
    "    inputs={\"corpus\": \"passage\"},\n",
    "    outputs={\"encoded_passage\": \"encoded_corpus\"},\n",
    "    map_over=\"corpus\",\n",
    ")\n",
    "\n",
    "\n",
    "@func(output=\"index\")\n",
    "def build_index(\n",
    "    indexer: Indexer, encoded_corpus: Sequence[EncodedPassage]\n",
    ") -> BaseIndex:\n",
    "    return indexer.index(encoded_corpus)\n",
    "\n",
    "\n",
    "# Take the mapped EncodedPassage list and build an index\n",
    "encode_and_index = Pipeline(nodes=[encode_corpus, build_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0616f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy data\n",
    "corpus: List[Passage] = [\n",
    "    Passage(pid=\"p1\", text=\"Hello World\"),\n",
    "    Passage(pid=\"p2\", text=\"The Quick Brown Fox\"),\n",
    "]\n",
    "\n",
    "encoder = NumpyRandomEncoder(dim=4)\n",
    "indexer = SimpleIndexer(dim=encoder.dim)\n",
    "encode_and_index.visualize()\n",
    "\n",
    "outputs = encode_and_index.run(\n",
    "    inputs={\n",
    "        \"corpus\": corpus,\n",
    "        \"encoder\": encoder,\n",
    "        \"indexer\": indexer,\n",
    "    }\n",
    ")\n",
    "index: BaseIndex = outputs[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1919788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Retrieval + Reranking --------------------------------------------------\n",
    "encode_query = NestedPipeline(\n",
    "    pipeline=single_encode,\n",
    "    inputs={\"query.text\": \"text\"},\n",
    "    outputs={\"encoded_passage\": \"query_vec\"},\n",
    ")\n",
    "\n",
    "\n",
    "@func(output=\"retrieved\")\n",
    "def retrieve(\n",
    "    index: BaseIndex, query_vec: Vector, top_k: int = 10\n",
    ") -> List[RetrievedDoc]:\n",
    "    hits = index.search(query_vec, top_k=top_k)\n",
    "    return [\n",
    "        RetrievedDoc(\n",
    "            pid=h[\"pid\"],\n",
    "            text=index.get(h[\"pid\"]).text,\n",
    "            embedding=index.get(h[\"pid\"]).embedding,\n",
    "            score=h[\"score\"],\n",
    "        )\n",
    "        for h in hits\n",
    "    ]\n",
    "\n",
    "\n",
    "@func(output=\"reranked_hits\")\n",
    "def rerank_hits(\n",
    "    reranker: Reranker,\n",
    "    query: Query,\n",
    "    retrieved: List[RetrievedDoc],\n",
    "    final_top_k: int | None = None,\n",
    ") -> List[RetrievedDoc]:\n",
    "    return reranker.rerank(query, retrieved, top_k=final_top_k)\n",
    "\n",
    "\n",
    "search_pipeline = Pipeline(nodes=[encode_query, retrieve, rerank_hits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f5c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline(nodes=[encode_and_index, search_pipeline])\n",
    "full_pipeline.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ff75f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    Passage(pid=\"p1\", text=\"Hello World\"),\n",
    "    Passage(pid=\"p2\", text=\"Quick Brown Fox\"),\n",
    "]\n",
    "encoder = NumpyRandomEncoder(dim=4)\n",
    "indexer = SimpleIndexer(dim=encoder.dim)\n",
    "\n",
    "outputs = encode_and_index.run(\n",
    "    inputs={\"passage\": corpus, \"encoder\": encoder, \"indexer\": indexer}\n",
    ")\n",
    "index: BaseIndex = outputs[\"index\"]\n",
    "\n",
    "reranker = IdentityReranker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f838d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single query\n",
    "search_out = search_pipeline.run(\n",
    "    inputs={\n",
    "        \"query\": Query(text=\"hello world\"),\n",
    "        \"encoder\": encoder,\n",
    "        \"index\": index,\n",
    "        \"reranker\": reranker,\n",
    "        \"top_k\": 5,\n",
    "        \"final_top_k\": 3,\n",
    "    }\n",
    ")\n",
    "\n",
    "for doc in search_out[\"reranked_hits\"]:\n",
    "    print(doc.pid, doc.score, doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59587584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Multiple queries ---------------------------------------------------\n",
    "queries = [Query(text=\"hello\"), Query(text=\"quick fox\"), Query(text=\"world\")]\n",
    "batch_out = search_pipeline.map(\n",
    "    inputs={\n",
    "        \"query\": queries,\n",
    "        \"encoder\": encoder,\n",
    "        \"index\": index,\n",
    "        \"reranker\": reranker,\n",
    "        \"top_k\": 5,\n",
    "        \"final_top_k\": 3,\n",
    "    },\n",
    "    map_over=\"query\",\n",
    ")\n",
    "\n",
    "for q, results in zip(queries, batch_out[\"reranked_hits\"]):\n",
    "    print(f\"\\nQuery: {q.text}\")\n",
    "    for r in results:\n",
    "        print(f\"  {r.pid} | {r.score:.3f} | {r.text}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
